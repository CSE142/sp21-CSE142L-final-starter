<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        Solutions: Final Project Part 1 - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);.hljs{display:block;background:#fff;padding:.5em;color:#333;overflow-x:auto}.hljs-comment,.hljs-meta{color:#969896}.hljs-emphasis,.hljs-quote,.hljs-string,.hljs-strong,.hljs-template-variable,.hljs-variable{color:#df5000}.hljs-keyword,.hljs-selector-tag,.hljs-type{color:#a71d5d}.hljs-attribute,.hljs-bullet,.hljs-literal,.hljs-number,.hljs-symbol{color:#0086b3}.hljs-built_in,.hljs-builtin-name{color:#005cc5}.hljs-name,.hljs-section{color:#63a35c}.hljs-tag{color:#333}.hljs-attr,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-title{color:#795da3}.hljs-addition{color:#55a532;background-color:#eaffea}.hljs-deletion{color:#bd2c00;background-color:#ffecec}.hljs-link{text-decoration:underline}.markdown-body{font-size:16px;line-height:1.5;word-wrap:break-word}.markdown-body:after,.markdown-body:before{display:table;content:""}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e7e7e7;border:0}.markdown-body blockquote{font-size:16px;padding:0 1em;color:#777;border-left:.25em solid #ddd}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#555;vertical-align:middle;background-color:#fcfcfc;border:1px solid #ccc;border-bottom-color:#bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{padding-bottom:.3em;border-bottom:1px solid #eee}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#777}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{padding:0;list-style-type:none}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:transparent}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{display:block;float:left;width:auto;padding:7px;margin:13px 0 0;overflow:hidden;border:1px solid #ddd}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{display:block;padding:5px 0 0;clear:both;color:#333}.markdown-body span.align-center{display:block;overflow:hidden;clear:both}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{display:block;overflow:hidden;clear:both}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{padding:0;padding-top:.2em;padding-bottom:.2em;margin:0;font-size:85%;background-color:rgba(0,0,0,.04);border-radius:3px}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{letter-spacing:-.2em;content:"\00a0"}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:transparent;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f7f7f7;border-radius:3px}.markdown-body pre code,.markdown-body pre tt{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{padding:5px;overflow:hidden;font-size:12px;line-height:1;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{padding:10px 8px 9px;text-align:right;background:#fff;border:0}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{font-weight:700;background:#f8f8f8;border-top:0}.news .alert .markdown-body blockquote{padding:0 0 0 40px;border:0 none}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle;cursor:default!important}.markdown-body{padding-top:40px;padding-bottom:40px;max-width:758px;overflow:visible!important;position:relative}.markdown-body .emoji{vertical-align:top}.markdown-body pre{border:inherit!important}.markdown-body code{color:inherit!important}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{text-align:right;position:relative;display:inline-block;cursor:default;z-index:4;padding:0 8px 0 0;min-width:20px;box-sizing:content-box;color:#afafaf!important;border-right:3px solid #6ce26c!important}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-left:none;border-top:none;border-bottom:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-spacing:0;border-collapse:inherit!important}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{overflow:unset;margin-bottom:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert>p{margin-bottom:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{text-align:center;background-color:inherit;border-radius:0;white-space:inherit;overflow:visible}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{max-width:100%;height:100%}.markdown-body pre>code.wrap{white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}.markdown-body .alert>p,.markdown-body .alert>ul{margin-bottom:0}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}.vimeo,.youtube{cursor:pointer;display:table;text-align:center;background-position:50%;background-repeat:no-repeat;background-size:contain;background-color:#000;overflow:hidden}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{width:100%;object-fit:contain;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{width:100%;height:100%;position:absolute;top:0;left:0}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{position:absolute;height:auto;width:auto;top:50%;left:50%;transform:translate(-50%,-50%);color:#fff;opacity:.3;transition:opacity .2s;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%}.figma{display:table;position:relative;width:100%;padding-bottom:56.25%}.figma iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%;border:1px solid #eee}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{position:relative;z-index:2;max-width:760px;margin:25px auto -25px;color:#777}.toc .invisable-node{list-style-type:none}.ui-toc{position:fixed;bottom:20px;z-index:998}.ui-toc.both-mode{margin-left:8px}.ui-toc.both-mode .ui-toc-label{height:40px;padding:10px 4px;border-top-left-radius:0;border-bottom-left-radius:0}.ui-toc-label{background-color:#e6e6e6;border:none;color:#868686;transition:opacity .2s}.ui-toc .open .ui-toc-label{opacity:1;color:#fff;transition:opacity .2s}.ui-toc-label:focus{opacity:.3;background-color:#ccc;color:#000}.ui-toc-label:hover{opacity:1;background-color:#ccc;transition:opacity .2s}.ui-toc-dropdown{margin-top:20px;margin-bottom:20px;padding-left:10px;padding-right:10px;max-width:45vw;width:25vw;max-height:70vh;overflow:auto;text-align:inherit}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{padding-right:0;letter-spacing:.0029em}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{display:block;padding:4px 20px;font-size:13px;font-weight:500;color:#767676}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{padding-left:19px;color:#000;text-decoration:none;background-color:transparent;border-left:1px solid #000}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{padding-right:19px;border-left:none;border-right:1px solid #000}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{padding-left:18px;font-weight:700;color:#000;background-color:transparent;border-left:2px solid #000}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{padding-right:18px;border-left:none;border-right:2px solid #000}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{padding-top:1px;padding-bottom:1px;padding-left:30px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{padding-top:1px;padding-bottom:1px;padding-left:40px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{padding-left:28px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{padding-left:38px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif}html[lang^=ja] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html .markdown-body[lang^=ja]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html .markdown-body[lang=zh-tw]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html .markdown-body[lang=zh-cn]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html[lang^=ja] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html[lang=zh-tw] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html[lang=zh-cn] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}html .ui-toc-dropdown[lang^=ja]{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html .ui-toc-dropdown[lang=zh-tw]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html .ui-toc-dropdown[lang=zh-cn]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}.ui-affix-toc{position:fixed;top:0;max-width:15vw;max-height:70vh;overflow:auto}.back-to-top,.expand-toggle,.go-to-bottom{display:block;padding:4px 10px;margin-top:10px;margin-left:10px;font-size:12px;font-weight:500;color:#999}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:#563d7c;text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{width:20px;height:20px;display:block;border-radius:50%;margin-top:2px;margin-bottom:2px;margin-right:5px;background-position:50%;background-repeat:no-repeat;background-size:cover}.ui-user-icon.small{width:18px;height:18px;display:inline-block;vertical-align:middle;margin:0 0 .2em}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{color:#888;cursor:pointer;vertical-align:middle}.ui-more-info .fa{font-size:16px}.ui-connectedGithub,.ui-published-note{color:#888}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{color:#888;text-decoration:none;padding-left:22px}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{color:#888;text-decoration:underline}.ui-connectedGithub .fa{font-size:20px}.ui-published-note .fa{font-size:20px;vertical-align:top}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{position:relative;z-index:1;color:#222}.markdown-body.slides:before{content:"";display:block;position:absolute;top:0;left:0;right:0;bottom:0;z-index:-1;background-color:currentColor;box-shadow:0 0 0 50vw}.markdown-body.slides section[data-markdown]{position:relative;margin-bottom:1.5em;background-color:#fff;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{position:absolute;top:50%;left:1em;right:1em;transform:translateY(-50%);max-height:100%;overflow:hidden}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{content:"";position:absolute;top:-1.5em;right:1em;height:1.5em;border:3px solid #777}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;text-shadow:0 0 1em transparent,1px 1px 1.2px rgba(0,0,0,.004);-webkit-overflow-scrolling:touch;letter-spacing:.025em;font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-inner comment-enabled" data-hard-breaks="true"><h1 id="Solutions-Final-Project-Part-1" data-id="Solutions-Final-Project-Part-1"><a class="anchor hidden-xs" href="#Solutions-Final-Project-Part-1" title="Solutions-Final-Project-Part-1"><span class="octicon octicon-link"></span></a><span>Solutions: Final Project Part 1</span></h1><hr><h3 id="Experience--O3" data-id="Experience--O3"><a class="anchor hidden-xs" href="#Experience--O3" title="Experience--O3"><span class="octicon octicon-link"></span></a><span>Experience </span><code>-O3</code></h3><p><span>Let’s see how much the compiler is helping us.  Set </span><code>OPTIMIZE=-O3</code><span> in </span><code>config.env</code><span>, and measure performance for our benchmark:</span></p><pre><code>runlab --run-git-remotely -- make benchmark.csv
</code></pre><h4 id="P1-1pt-Provide-the-runtime-for-train_model-reported-in-benchmarkcsv" data-id="P1-1pt-Provide-the-runtime-for-train_model-reported-in-benchmarkcsv"><a class="anchor hidden-xs" href="#P1-1pt-Provide-the-runtime-for-train_model-reported-in-benchmarkcsv" title="P1-1pt-Provide-the-runtime-for-train_model-reported-in-benchmarkcsv"><span class="octicon octicon-link"></span></a><span>P1 (1pt): Provide the runtime for </span><code>train_model</code><span> reported in </span><code>benchmark.csv</code><span>.</span></h4><pre><code>-O3 execution time: 20.9s
</code></pre><p><span>The set </span><code>OPTIMIZE=-O0</code><span> and run it again.</span></p><h4 id="P1-1pt-Provide-the-runtime-for-train_model-in-benchmarkcsv" data-id="P1-1pt-Provide-the-runtime-for-train_model-in-benchmarkcsv"><a class="anchor hidden-xs" href="#P1-1pt-Provide-the-runtime-for-train_model-in-benchmarkcsv" title="P1-1pt-Provide-the-runtime-for-train_model-in-benchmarkcsv"><span class="octicon octicon-link"></span></a><span>P1 (1pt): Provide the runtime for </span><code>train_model</code><span> in </span><code>benchmark.csv</code><span>.</span></h4><pre><code>-OO execution time: 198s

Speedup from -O3: ~9.5X
</code></pre><h3 id="Get-Yourself-a-Map" data-id="Get-Yourself-a-Map"><a class="anchor hidden-xs" href="#Get-Yourself-a-Map" title="Get-Yourself-a-Map"><span class="octicon octicon-link"></span></a><span>Get Yourself a Map</span></h3><p><span>Next, we analyze the performance of the existing code and figure out which functions are taking majority of the execution time in this new CNN architecture of ours.</span></p><p><span>To generate benchmark results, first enable </span><code>gprof</code><span> by uncomment the line </span><code>GROF=yes</code><span> and set </span><code>OPTIMIZE=-O3</code><span>.  Commit, push, and run </span><code>make benchmark.csv</code><span> again with </span><code>--run-git-remotely</code><span>.</span></p><p><span>Examine the output in </span><code>benchmark.gprof</code><span> and answer the following:</span></p><h4 id="P3-3pt-List-the-functions-as-listed-in-benchmarkgprof-that-combined-to-account-for-99-of-the-total-execution-time-Report-the-percent-proportions-as-well" data-id="P3-3pt-List-the-functions-as-listed-in-benchmarkgprof-that-combined-to-account-for-99-of-the-total-execution-time-Report-the-percent-proportions-as-well"><a class="anchor hidden-xs" href="#P3-3pt-List-the-functions-as-listed-in-benchmarkgprof-that-combined-to-account-for-99-of-the-total-execution-time-Report-the-percent-proportions-as-well" title="P3-3pt-List-the-functions-as-listed-in-benchmarkgprof-that-combined-to-account-for-99-of-the-total-execution-time-Report-the-percent-proportions-as-well"><span class="octicon octicon-link"></span></a><span>P3 (3pt): List the functions (as listed in </span><code>benchmark.gprof</code><span>) that combined to account for 99% of the total execution time. Report the percent proportions as well.</span></h4><pre><code>conv_layer_t::calc_grads(tensor_t&lt;double&gt; const&amp;)
conv_layer_t::activate(tensor_t&lt;double&gt;&amp;)
fc_layer_t::activate(tensor_t&lt;double&gt;&amp;)
fc_layer_t::fix_weights()
conv_layer_t::fix_weights()
fc_layer_t::calc_grads

-- Atleast top 4 required
</code></pre><p><strong><span>Note:</span></strong><span> Remember to turn of </span><code>gprof</code><span> when you dont need it.  It adds overhead.</span></p><h3 id="Tile-fc_layer_tactivate" data-id="Tile-fc_layer_tactivate"><a class="anchor hidden-xs" href="#Tile-fc_layer_tactivate" title="Tile-fc_layer_tactivate"><span class="octicon octicon-link"></span></a><span>Tile </span><code>fc_layer_t::activate</code></h3><p><span>In the starter code you’ll find an implemententation of </span><code>fc_layer_t::activate</code><span> that tiles all three loops based on the iteration space analysis I did during the lecture for the lab.</span></p><p><strong><span>Note</span></strong><span> This means you should look at the table in the slides and select the tile sizes that, according to my analysis, would provide the lowest cache miss rate.  That is the implementation you should mesaure in P3 and P4 below.  You don’t need to run multiple experiments to compare different tile sizes for those problems.  You’ll do that in P5 and P6.</span></p><p><span>Compare the performance of the resulting code to the original code in </span><code>fc_layer_t.hpp</code><span> (i.e, </span><code>fc_layer_t::activate</code><span>) on layer 14 of the model. You should get a speedup of 9-10x.</span></p><p><span>Use the </span><code>--param*</code><span> command line options to do this in one run.</span></p><h4 id="P3-3pt-Write-the-runlab-command-and-the-values-of-CMD_LINE_ARGS-and-IMPL_SEL_ARGS-used-to-compare-your-optimization-with-the-original-code" data-id="P3-3pt-Write-the-runlab-command-and-the-values-of-CMD_LINE_ARGS-and-IMPL_SEL_ARGS-used-to-compare-your-optimization-with-the-original-code"><a class="anchor hidden-xs" href="#P3-3pt-Write-the-runlab-command-and-the-values-of-CMD_LINE_ARGS-and-IMPL_SEL_ARGS-used-to-compare-your-optimization-with-the-original-code" title="P3-3pt-Write-the-runlab-command-and-the-values-of-CMD_LINE_ARGS-and-IMPL_SEL_ARGS-used-to-compare-your-optimization-with-the-original-code"><span class="octicon octicon-link"></span></a><span>P3 (3pt) Write the </span><code>runlab</code><span> command and the values of </span><code>CMD_LINE_ARGS</code><span> and </span><code>IMPL_SEL_ARGS</code><span> used to compare your optimization with the original code</span></h4><pre><code>runlab command: runlab --run-git-remotely --make cnn.csv

CMD_LINE_ARGS: --scale 2 --test-layer 14 --function activate

IMPL_SEL_ARGS: --param1-name activate_impl --param1 0 1  --param2-name i_tile_size --param2 1 64 -- --param3-name b_tile_size --param3 1 4 --param4-name n_tile_size --param4 1 32

</code></pre><h4 id="P4-1pt-Note-down-the-both-execution-times-and-calculate-the-speedup" data-id="P4-1pt-Note-down-the-both-execution-times-and-calculate-the-speedup"><a class="anchor hidden-xs" href="#P4-1pt-Note-down-the-both-execution-times-and-calculate-the-speedup" title="P4-1pt-Note-down-the-both-execution-times-and-calculate-the-speedup"><span class="octicon octicon-link"></span></a><span>P4 (1pt) Note down the both execution times, and calculate the speedup</span></h4><pre><code>Original execution time: (Depends on scale)

Optimized execution time: (Depends on scale)

Speedup: 8X - 12X

</code></pre><h4 id="P5-4pt-Use---param-to-explore-the-range-of-tiling-sizes-for-activate-Draw-a-graph-that-shows-the-impact-on-execution-time-of-tiling-I-and-N-at-tile-sizes-from-1-to-128-all-combinations-Make-sure-it-is-clearly-labeled-legible-You-are-plotting-execution-time-against-two-variables-so-you-will-need-to-account-for-that-in-the-graph" data-id="P5-4pt-Use---param-to-explore-the-range-of-tiling-sizes-for-activate-Draw-a-graph-that-shows-the-impact-on-execution-time-of-tiling-I-and-N-at-tile-sizes-from-1-to-128-all-combinations-Make-sure-it-is-clearly-labeled-legible-You-are-plotting-execution-time-against-two-variables-so-you-will-need-to-account-for-that-in-the-graph"><a class="anchor hidden-xs" href="#P5-4pt-Use---param-to-explore-the-range-of-tiling-sizes-for-activate-Draw-a-graph-that-shows-the-impact-on-execution-time-of-tiling-I-and-N-at-tile-sizes-from-1-to-128-all-combinations-Make-sure-it-is-clearly-labeled-legible-You-are-plotting-execution-time-against-two-variables-so-you-will-need-to-account-for-that-in-the-graph" title="P5-4pt-Use---param-to-explore-the-range-of-tiling-sizes-for-activate-Draw-a-graph-that-shows-the-impact-on-execution-time-of-tiling-I-and-N-at-tile-sizes-from-1-to-128-all-combinations-Make-sure-it-is-clearly-labeled-legible-You-are-plotting-execution-time-against-two-variables-so-you-will-need-to-account-for-that-in-the-graph"><span class="octicon octicon-link"></span></a><span>P5 (4pt) Use </span><code>--param*</code><span> to explore the range of tiling sizes for </span><code>activate()</code><span>.  Draw a graph that shows the impact on execution time of tiling </span><code>I</code><span> and </span><code>N</code><span> at tile sizes from 1 to 128 (all combinations).  Make sure it is clearly labeled legible.  You are plotting execution time against two variables, so you will need to account for that in the graph.</span></h4><pre><code>




Your graph here






</code></pre><h4 id="P6-2pt-Based-on-your-data-what-are-the-optimal-tile-sizes-How-much-speedup-do-the-optimal-sizes-provide-relative-to-the-performance-you-measured-for-P4" data-id="P6-2pt-Based-on-your-data-what-are-the-optimal-tile-sizes-How-much-speedup-do-the-optimal-sizes-provide-relative-to-the-performance-you-measured-for-P4"><a class="anchor hidden-xs" href="#P6-2pt-Based-on-your-data-what-are-the-optimal-tile-sizes-How-much-speedup-do-the-optimal-sizes-provide-relative-to-the-performance-you-measured-for-P4" title="P6-2pt-Based-on-your-data-what-are-the-optimal-tile-sizes-How-much-speedup-do-the-optimal-sizes-provide-relative-to-the-performance-you-measured-for-P4"><span class="octicon octicon-link"></span></a><span>P6 (2pt) Based on your data, what are the optimal tile sizes?  How much speedup do the optimal sizes provide relative to the performance you measured for P4?</span></h4><pre><code>Optimal I_TILE_SIZE: 32

Optimal B_TILE_SIZE: 4

Optimal N_TILE_SIZE: 64

Speedup of Optimal over P4: 1.2X - 1.6X

-- Optimal sizes may vary in your experiments, will be graded based on the graph

</code></pre><h1 id="Solutions-Final-Project-Part-2---Threads" data-id="Solutions-Final-Project-Part-2---Threads"><a class="anchor hidden-xs" href="#Solutions-Final-Project-Part-2---Threads" title="Solutions-Final-Project-Part-2---Threads"><span class="octicon octicon-link"></span></a><span>Solutions: Final Project Part 2 - Threads</span></h1><h4 id="P1-1pt-Which-implementation-provide-the-best-performance-The-worst" data-id="P1-1pt-Which-implementation-provide-the-best-performance-The-worst"><a class="anchor hidden-xs" href="#P1-1pt-Which-implementation-provide-the-best-performance-The-worst" title="P1-1pt-Which-implementation-provide-the-best-performance-The-worst"><span class="octicon octicon-link"></span></a><span>P1 (1pt): Which implementation provide the best performance? The worst?</span></h4><pre><code>Best OMP implementation: NN implementation, Case 2, 0.053 seconds

Worst OMP implementation: N implementation, Case 4, 0.348 seconds

PS: Runtimes could vary. The values have been judged based on answers in P2.


dataset|training_inputs_count|omp_threads|activate_impl|calc_grads_impl|param3|param4|full_name                        |function  |layer|layer_type|reps|misses  |IC      |cycles  |runtime|PAPI_REF_CYC|MHz    |TIC     |Tmisses |IPC  |CT      |CPI  |ET   |
-------|---------------------|-----------|-------------|---------------|------|------|---------------------------------|----------|-----|----------|----|--------|--------|--------|-------|------------|-------|--------|--------|-----|--------|-----|-----|
mininet|4.0                  |1.0        |1.0          |1.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |8.43e+07|1.35e+09|6.7e+08 |0.355  |7.03e+08    |1.9e+03|1.35e+09|8.43e+07|2.02 |5.29e-10|0.495|0.355|
mininet|4.0                  |1.0        |1.0          |2.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |1.27e+08|1.65e+09|8.39e+08|0.444  |8.8e+08     |1.9e+03|1.65e+09|1.27e+08|1.97 |5.29e-10|0.508|0.444|
mininet|4.0                  |1.0        |1.0          |3.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |8.48e+07|1.36e+09|6.03e+08|0.323  |6.33e+08    |1.9e+03|1.36e+09|8.48e+07|2.25 |5.36e-10|0.444|0.323|
mininet|4.0                  |1.0        |1.0          |4.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |2.16e+08|2.6e+09 |1.22e+09|0.664  |1.28e+09    |1.9e+03|2.6e+09 |2.16e+08|2.12 |5.43e-10|0.471|0.664|
mininet|4.0                  |1.0        |1.0          |5.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |8.94e+07|1.44e+09|6.53e+08|0.413  |6.86e+08    |1.9e+03|1.44e+09|8.94e+07|2.2  |6.32e-10|0.455|0.413|
mininet|4.0                  |2.0        |1.0          |1.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |8.43e+07|1.35e+09|6.71e+08|0.355  |7.04e+08    |1.9e+03|2.71e+09|1.69e+08|2.02 |5.29e-10|0.496|0.355|
mininet|4.0                  |2.0        |1.0          |2.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |6.47e+07|8.29e+08|4.62e+08|0.245  |4.84e+08    |1.9e+03|1.66e+09|1.29e+08|1.8  |5.31e-10|0.557|0.245|
mininet|4.0                  |2.0        |1.0          |3.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |4.26e+07|6.84e+08|4.39e+08|0.238  |4.61e+08    |1.9e+03|1.37e+09|8.51e+07|1.56 |5.42e-10|0.642|0.238|
mininet|4.0                  |2.0        |1.0          |4.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |1.28e+08|1.31e+09|1.09e+09|0.596  |1.15e+09    |1.9e+03|2.63e+09|2.56e+08|1.2  |5.46e-10|0.831|0.596|
mininet|4.0                  |2.0        |1.0          |5.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |4.03e+07|7.43e+08|5.51e+08|0.334  |5.79e+08    |1.9e+03|1.49e+09|8.06e+07|1.35 |6.05e-10|0.742|0.334|
mininet|4.0                  |4.0        |1.0          |1.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |8.43e+07|1.35e+09|6.7e+08 |0.354  |7.03e+08    |1.9e+03|5.41e+09|3.37e+08|2.02 |5.28e-10|0.495|0.354|
mininet|4.0                  |4.0        |1.0          |2.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |3.36e+07|4.18e+08|2.42e+08|0.129  |2.54e+08    |1.9e+03|1.67e+09|1.35e+08|1.73 |5.33e-10|0.578|0.129|
mininet|4.0                  |4.0        |1.0          |3.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |2.15e+07|3.48e+08|3.5e+08 |0.191  |3.67e+08    |1.9e+03|1.39e+09|8.62e+07|0.995|5.45e-10|1.01 |0.191|
mininet|4.0                  |4.0        |1.0          |4.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |6.24e+07|6.95e+08|1.1e+09 |0.59   |1.16e+09    |1.9e+03|2.78e+09|2.5e+08 |0.631|5.36e-10|1.58 |0.59 |
mininet|4.0                  |4.0        |1.0          |5.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |1.56e+07|4.13e+08|2.98e+08|0.285  |3.14e+08    |1.9e+03|1.65e+09|6.23e+07|1.39 |9.54e-10|0.722|0.285|
mininet|4.0                  |8.0        |1.0          |1.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |8.43e+07|1.35e+09|6.7e+08 |0.354  |7.03e+08    |1.9e+03|1.08e+10|6.74e+08|2.02 |5.29e-10|0.495|0.354|
mininet|4.0                  |8.0        |1.0          |2.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |1.63e+07|2.15e+08|2.66e+08|0.142  |2.79e+08    |1.9e+03|1.72e+09|1.3e+08 |0.809|5.35e-10|1.24 |0.142|
mininet|4.0                  |8.0        |1.0          |3.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |1.67e+07|3.5e+08 |5.41e+08|0.296  |5.68e+08    |1.9e+03|2.8e+09 |1.33e+08|0.646|5.48e-10|1.55 |0.296|
mininet|4.0                  |8.0        |1.0          |4.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |6.45e+07|7.06e+08|1.41e+09|0.767  |1.47e+09    |1.9e+03|5.65e+09|5.16e+08|0.502|5.45e-10|1.99 |0.767|
mininet|4.0                  |8.0        |1.0          |5.0            |1.0   |1.0   |layer[14]-&gt;calc_grads  fc_layer_t|calc_grads|14.0 |fc_layer_t|5.0 |9.85e+06|2.69e+08|3.58e+08|0.336  |3.76e+08    |1.9e+03|2.15e+09|7.88e+07|0.752|9.39e-10|1.33 |0.336|
</code></pre><h4 id="P2-10pts-Draw-5-graphs-one-for-each-of-the-5-implementations-calc_grads_thread_baseline-and-the-four-variations-Each-one-should-plot-the-normalized-values-for-the-first-7-values-misses-through-ET-in-the-table-above-in-the-data-you-collected-above-y-axis-vs-thread-count-x-axis-The-graphs-their-axes-and-their-legends-should-be-clearly-labeled-eg-‘calc_grads_thread_baseline_nn’-I’ll-do-an-example-of-how-to-draw-these-graphs-efficiently-in-class" data-id="P2-10pts-Draw-5-graphs-one-for-each-of-the-5-implementations-calc_grads_thread_baseline-and-the-four-variations-Each-one-should-plot-the-normalized-values-for-the-first-7-values-misses-through-ET-in-the-table-above-in-the-data-you-collected-above-y-axis-vs-thread-count-x-axis-The-graphs-their-axes-and-their-legends-should-be-clearly-labeled-eg-‘calc_grads_thread_baseline_nn’-I’ll-do-an-example-of-how-to-draw-these-graphs-efficiently-in-class"><a class="anchor hidden-xs" href="#P2-10pts-Draw-5-graphs-one-for-each-of-the-5-implementations-calc_grads_thread_baseline-and-the-four-variations-Each-one-should-plot-the-normalized-values-for-the-first-7-values-misses-through-ET-in-the-table-above-in-the-data-you-collected-above-y-axis-vs-thread-count-x-axis-The-graphs-their-axes-and-their-legends-should-be-clearly-labeled-eg-‘calc_grads_thread_baseline_nn’-I’ll-do-an-example-of-how-to-draw-these-graphs-efficiently-in-class" title="P2-10pts-Draw-5-graphs-one-for-each-of-the-5-implementations-calc_grads_thread_baseline-and-the-four-variations-Each-one-should-plot-the-normalized-values-for-the-first-7-values-misses-through-ET-in-the-table-above-in-the-data-you-collected-above-y-axis-vs-thread-count-x-axis-The-graphs-their-axes-and-their-legends-should-be-clearly-labeled-eg-‘calc_grads_thread_baseline_nn’-I’ll-do-an-example-of-how-to-draw-these-graphs-efficiently-in-class"><span class="octicon octicon-link"></span></a><span>P2 (10pts):  Draw 5 graphs, one for each of the 5 implementations (</span><code>calc_grads_thread_baseline()</code><span> and the four variations).  Each one should plot the normalized values for the first 7 values (</span><code>misses</code><span> through </span><code>ET</code><span> in the table above) in the data you collected above (y-axis) vs. thread count (x-axis).  The graphs, their axes, and their legends should be clearly labeled (e.g., ‘calc_grads_thread_baseline_nn()’).  I’ll do an example of how to draw these graphs efficiently in class.</span></h4><p><img src="https://i.imgur.com/PTFEvm3.png" alt="" loading="lazy"><br>
<img src="https://i.imgur.com/P8VEi0x.png" alt="" loading="lazy"><br>
<img src="https://i.imgur.com/VWtffGi.png" alt="" loading="lazy"><br>
<img src="https://i.imgur.com/Gt4alyr.png" alt="" loading="lazy"></p><h4 id="P3-1-pt-Best-Implementation-and-thread-count" data-id="P3-1-pt-Best-Implementation-and-thread-count"><a class="anchor hidden-xs" href="#P3-1-pt-Best-Implementation-and-thread-count" title="P3-1-pt-Best-Implementation-and-thread-count"><span class="octicon octicon-link"></span></a><span>P3 (1 pt): Best Implementation and thread count</span></h4><p><code>Baseline_nn and 4 threads</code></p><h4 id="P4-2-pts-Consider-Version-3-b-loop-Use-the-Moneta-trace-to-determine-aptly-how-many-kBs-of-grads_out-each-thread-accesses-and-roughly-how-many-times-it-accesses-those-bytes-Provide-and-label-one-screen-capture-how-these-values-were-arrived-at" data-id="P4-2-pts-Consider-Version-3-b-loop-Use-the-Moneta-trace-to-determine-aptly-how-many-kBs-of-grads_out-each-thread-accesses-and-roughly-how-many-times-it-accesses-those-bytes-Provide-and-label-one-screen-capture-how-these-values-were-arrived-at"><a class="anchor hidden-xs" href="#P4-2-pts-Consider-Version-3-b-loop-Use-the-Moneta-trace-to-determine-aptly-how-many-kBs-of-grads_out-each-thread-accesses-and-roughly-how-many-times-it-accesses-those-bytes-Provide-and-label-one-screen-capture-how-these-values-were-arrived-at" title="P4-2-pts-Consider-Version-3-b-loop-Use-the-Moneta-trace-to-determine-aptly-how-many-kBs-of-grads_out-each-thread-accesses-and-roughly-how-many-times-it-accesses-those-bytes-Provide-and-label-one-screen-capture-how-these-values-were-arrived-at"><span class="octicon octicon-link"></span></a><span>P4 (2 pts): Consider Version 3 (b loop). Use the Moneta trace to determine aptly how many kBs of </span><code>grads_out</code><span> each thread accesses and roughly how many times it accesses those bytes. Provide and label one screen capture how these values were arrived at.</span></h4><pre><code>    Each thread accesses ~ 32 kB
    Each element is accessed ****too many to count**** times
</code></pre><p><img src="https://i.imgur.com/ENYnQwL.png" alt="" loading="lazy"></p><h4 id="P5-2-pts-Consider-Version-3-b-loop-Provide-a-screen-capture-of-weights-Approximately-how-large-is-weights-tensor-in-kB" data-id="P5-2-pts-Consider-Version-3-b-loop-Provide-a-screen-capture-of-weights-Approximately-how-large-is-weights-tensor-in-kB"><a class="anchor hidden-xs" href="#P5-2-pts-Consider-Version-3-b-loop-Provide-a-screen-capture-of-weights-Approximately-how-large-is-weights-tensor-in-kB" title="P5-2-pts-Consider-Version-3-b-loop-Provide-a-screen-capture-of-weights-Approximately-how-large-is-weights-tensor-in-kB"><span class="octicon octicon-link"></span></a><span>P5 (2 pts): Consider Version 3 (b loop). Provide a screen capture of </span><code>weights</code><span>. Approximately, how large is weights tensor in kB?</span></h4><p><img src="https://i.imgur.com/hAPNr6o.png" alt="" loading="lazy"></p><pre><code>    Size of weights tensor = 120,000 kB
    How many times is each element accessed = 4
</code></pre><h4 id="P6-2-pts-What-did-you-learn-from-P4-and-P5-that-could-explain-the-high-CPI-for-version-3-b-loop" data-id="P6-2-pts-What-did-you-learn-from-P4-and-P5-that-could-explain-the-high-CPI-for-version-3-b-loop"><a class="anchor hidden-xs" href="#P6-2-pts-What-did-you-learn-from-P4-and-P5-that-could-explain-the-high-CPI-for-version-3-b-loop" title="P6-2-pts-What-did-you-learn-from-P4-and-P5-that-could-explain-the-high-CPI-for-version-3-b-loop"><span class="octicon octicon-link"></span></a><span>P6 (2 pts): What did you learn from P4 and P5 that could explain the high CPI for version 3 (b loop)?</span></h4><pre><code>    Simply increasing the number of threads doesn't aid in increasing the performance of the application. There are capacity misses caused by increasing the thread count. This explains the higher CPI. When one thread tries to use an element, the other thread tries to evict it resulting in a high cache miss rate and CPI.
</code></pre><h4 id="P7-2-pts-Consider-calc_grads_thread_baseline_n-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-How-many-times-does-it-accesses-each-entry-of-the-tensor-Provide-and-label-a-Moneta-screen-capture-that-supports-your-conclusions" data-id="P7-2-pts-Consider-calc_grads_thread_baseline_n-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-How-many-times-does-it-accesses-each-entry-of-the-tensor-Provide-and-label-a-Moneta-screen-capture-that-supports-your-conclusions"><a class="anchor hidden-xs" href="#P7-2-pts-Consider-calc_grads_thread_baseline_n-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-How-many-times-does-it-accesses-each-entry-of-the-tensor-Provide-and-label-a-Moneta-screen-capture-that-supports-your-conclusions" title="P7-2-pts-Consider-calc_grads_thread_baseline_n-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-How-many-times-does-it-accesses-each-entry-of-the-tensor-Provide-and-label-a-Moneta-screen-capture-that-supports-your-conclusions"><span class="octicon octicon-link"></span></a><span>P7 (2 pts): Consider </span><code>calc_grads_thread_baseline_n()</code><span> How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? How many times does it accesses each entry of the tensor? Provide and label a Moneta screen capture that supports your conclusions.</span></h4><pre><code>    Each entry of the weights tensor is accessed 4 times

    The working set size = 32 kB
</code></pre><p><img src="https://i.imgur.com/Sdh1HPc.png" alt="" loading="lazy"></p><h4 id="P8-2-pts-Consider-calc_grads_thread_baseline_n-What’s-the-ratio-of-IC-on-calc_grads_thread_baseline-to-IC-on-calc_grads_thread_baseline_n-with-1-thread-Paste-in-a-copy-of-the-C-code-that-corresponds-to-the-extra-instructions" data-id="P8-2-pts-Consider-calc_grads_thread_baseline_n-What’s-the-ratio-of-IC-on-calc_grads_thread_baseline-to-IC-on-calc_grads_thread_baseline_n-with-1-thread-Paste-in-a-copy-of-the-C-code-that-corresponds-to-the-extra-instructions"><a class="anchor hidden-xs" href="#P8-2-pts-Consider-calc_grads_thread_baseline_n-What’s-the-ratio-of-IC-on-calc_grads_thread_baseline-to-IC-on-calc_grads_thread_baseline_n-with-1-thread-Paste-in-a-copy-of-the-C-code-that-corresponds-to-the-extra-instructions" title="P8-2-pts-Consider-calc_grads_thread_baseline_n-What’s-the-ratio-of-IC-on-calc_grads_thread_baseline-to-IC-on-calc_grads_thread_baseline_n-with-1-thread-Paste-in-a-copy-of-the-C-code-that-corresponds-to-the-extra-instructions"><span class="octicon octicon-link"></span></a><span>P8 (2 pts) Consider calc_grads_thread_baseline_n(). What’s the ratio of IC on calc_grads_thread_baseline() to IC on calc_grads_thread_baseline_n() with 1 thread? Paste in a copy of the C++ code that corresponds to the extra instructions.</span></h4><pre><code>    IC Ratio = 1.35 x 10^9 / 2.6 x 10^9 ~= 0.5194 (2)
    
    #pragma omp critical
    for (int i = 0; i &lt; grads_out.size.x; i++) {
        grads_out(i, 0, 0, b) += grads_out_local(i,0,0,0);     
    }

</code></pre><h4 id="P9-2-pts-Consider-calc_grads_thread_baseline_i-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-Give-your-answer-in-KB-Provide-and-label-a-screen-capture-illustrating-your-conclusion" data-id="P9-2-pts-Consider-calc_grads_thread_baseline_i-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-Give-your-answer-in-KB-Provide-and-label-a-screen-capture-illustrating-your-conclusion"><a class="anchor hidden-xs" href="#P9-2-pts-Consider-calc_grads_thread_baseline_i-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-Give-your-answer-in-KB-Provide-and-label-a-screen-capture-illustrating-your-conclusion" title="P9-2-pts-Consider-calc_grads_thread_baseline_i-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-Give-your-answer-in-KB-Provide-and-label-a-screen-capture-illustrating-your-conclusion"><span class="octicon octicon-link"></span></a><span>P9 (2 pts) Consider calc_grads_thread_baseline_i(). How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? Give your answer in KB. Provide and label a screen capture illustrating your conclusion.</span></h4><pre><code>    Working set size = 8 kB (4 threads access 8 kB each for baseline_i)
</code></pre><p><img src="https://i.imgur.com/T1q1PXT.png" alt="" loading="lazy"></p><h4 id="P10-2-pts-Consider-calc_grads_thread_baseline_i-How-much-in-KB-of-grads_out-tensor-is-does-each-thread-access-Provide-and-label-a-screen-capture-illustrating-your-conclusion" data-id="P10-2-pts-Consider-calc_grads_thread_baseline_i-How-much-in-KB-of-grads_out-tensor-is-does-each-thread-access-Provide-and-label-a-screen-capture-illustrating-your-conclusion"><a class="anchor hidden-xs" href="#P10-2-pts-Consider-calc_grads_thread_baseline_i-How-much-in-KB-of-grads_out-tensor-is-does-each-thread-access-Provide-and-label-a-screen-capture-illustrating-your-conclusion" title="P10-2-pts-Consider-calc_grads_thread_baseline_i-How-much-in-KB-of-grads_out-tensor-is-does-each-thread-access-Provide-and-label-a-screen-capture-illustrating-your-conclusion"><span class="octicon octicon-link"></span></a><span>P10 (2 pts) Consider calc_grads_thread_baseline_i(). How much (in KB) of grads_out tensor is does each thread access? Provide and label a screen capture illustrating your conclusion.</span></h4><pre><code>    Working set size = 8 kB
</code></pre><p><img src="https://i.imgur.com/ZjE1cME.png" alt="" loading="lazy"></p><h4 id="P11-2pts-Use-your-answers-to-P9-and-P10-and-similar-measurements-of-the-trace-of-calc_grads_thread_baseline-to-explain-the-difference-between-the-number-of-misses-in-calc_grads_thread_baseline_i-and-calc_grads_thread_baseline-Two-sentences-max" data-id="P11-2pts-Use-your-answers-to-P9-and-P10-and-similar-measurements-of-the-trace-of-calc_grads_thread_baseline-to-explain-the-difference-between-the-number-of-misses-in-calc_grads_thread_baseline_i-and-calc_grads_thread_baseline-Two-sentences-max"><a class="anchor hidden-xs" href="#P11-2pts-Use-your-answers-to-P9-and-P10-and-similar-measurements-of-the-trace-of-calc_grads_thread_baseline-to-explain-the-difference-between-the-number-of-misses-in-calc_grads_thread_baseline_i-and-calc_grads_thread_baseline-Two-sentences-max" title="P11-2pts-Use-your-answers-to-P9-and-P10-and-similar-measurements-of-the-trace-of-calc_grads_thread_baseline-to-explain-the-difference-between-the-number-of-misses-in-calc_grads_thread_baseline_i-and-calc_grads_thread_baseline-Two-sentences-max"><span class="octicon octicon-link"></span></a><span>P11 (2pts) Use your answers to P9 and P10 and similar measurements of the trace of calc_grads_thread_baseline() to explain the difference between the number of misses in calc_grads_thread_baseline_i() and calc_grads_thread_baseline(). Two sentences max.</span></h4><pre><code>    For weights, the access is for grads_out and weights. The working set size is 8 kB. The increase in thread count ensures there are fewer capacity misses and improves the overall spatial locality. 
    As thread count is increased, baseline_i performs better than baseline.
</code></pre><h4 id="P12-5pts-Compare-the-data-for-calc_grads_thread_baseline_nn-and-calc_grads_thread_baseline_i-with-4-threads-using-all-three-terms-of-the-PE-IC-CPI-and-CT-For-each-term-compute-value-for-calc_grads_thread_baseline_ivalue-for-calc_grads_thread_baseline_nn-Which-term-explains-calc_grads_thread_baseline_nns-lower-ET-What-could-be-one-underlying-cause-2-sentences-max" data-id="P12-5pts-Compare-the-data-for-calc_grads_thread_baseline_nn-and-calc_grads_thread_baseline_i-with-4-threads-using-all-three-terms-of-the-PE-IC-CPI-and-CT-For-each-term-compute-value-for-calc_grads_thread_baseline_ivalue-for-calc_grads_thread_baseline_nn-Which-term-explains-calc_grads_thread_baseline_nns-lower-ET-What-could-be-one-underlying-cause-2-sentences-max"><a class="anchor hidden-xs" href="#P12-5pts-Compare-the-data-for-calc_grads_thread_baseline_nn-and-calc_grads_thread_baseline_i-with-4-threads-using-all-three-terms-of-the-PE-IC-CPI-and-CT-For-each-term-compute-value-for-calc_grads_thread_baseline_ivalue-for-calc_grads_thread_baseline_nn-Which-term-explains-calc_grads_thread_baseline_nns-lower-ET-What-could-be-one-underlying-cause-2-sentences-max" title="P12-5pts-Compare-the-data-for-calc_grads_thread_baseline_nn-and-calc_grads_thread_baseline_i-with-4-threads-using-all-three-terms-of-the-PE-IC-CPI-and-CT-For-each-term-compute-value-for-calc_grads_thread_baseline_ivalue-for-calc_grads_thread_baseline_nn-Which-term-explains-calc_grads_thread_baseline_nns-lower-ET-What-could-be-one-underlying-cause-2-sentences-max"><span class="octicon octicon-link"></span></a><span>P12 (5pts) Compare the data for calc_grads_thread_baseline_nn() and calc_grads_thread_baseline_i() with 4 threads using all three terms of the PE (IC, CPI, and CT). For each term compute (value for calc_grads_thread_baseline_i)/(value for calc_grads_thread_baseline_nn). Which term explains calc_grads_thread_baseline_nn()'s lower ET? What could be one underlying cause? (2 sentences max)</span></h4><pre><code>    IC Ratio = 4.13 * 10^8 / 4.18 * 10^8 = 0.988
        
    CPI Ratio = 0.722 / 0.578 = 1.25
    
    CT Ratio = 9.54 * 10^-10 / 5.33 * 10^ -10 = 2
    
    Cycle time difference is the cause. 
    This could be because of thermal throttling where baseline_i() is running at a lower frequency (higher cycle time)

</code></pre><h1 id="Solutions-Final-Project-Part-3---Vectors" data-id="Solutions-Final-Project-Part-3---Vectors"><a class="anchor hidden-xs" href="#Solutions-Final-Project-Part-3---Vectors" title="Solutions-Final-Project-Part-3---Vectors"><span class="octicon octicon-link"></span></a><span>Solutions: Final Project Part 3 - Vectors</span></h1><h4 id="P1-1pts-Add--O3--fopt-info-vec-optimized-to-MICROBENCH_OPTIMIZE-in-configenv-and-then-runlab---run-git-remotely----make-buildmicrobencho-to-generate-the-optimization-report-It’ll-show-up-in-the-terminal-and-STDOUTtxt-Paste-in-the-lines-that-contain-the-string-microbenchcpp-below-there-will-be-less-than-10-of-them" data-id="P1-1pts-Add--O3--fopt-info-vec-optimized-to-MICROBENCH_OPTIMIZE-in-configenv-and-then-runlab---run-git-remotely----make-buildmicrobencho-to-generate-the-optimization-report-It’ll-show-up-in-the-terminal-and-STDOUTtxt-Paste-in-the-lines-that-contain-the-string-microbenchcpp-below-there-will-be-less-than-10-of-them"><a class="anchor hidden-xs" href="#P1-1pts-Add--O3--fopt-info-vec-optimized-to-MICROBENCH_OPTIMIZE-in-configenv-and-then-runlab---run-git-remotely----make-buildmicrobencho-to-generate-the-optimization-report-It’ll-show-up-in-the-terminal-and-STDOUTtxt-Paste-in-the-lines-that-contain-the-string-microbenchcpp-below-there-will-be-less-than-10-of-them" title="P1-1pts-Add--O3--fopt-info-vec-optimized-to-MICROBENCH_OPTIMIZE-in-configenv-and-then-runlab---run-git-remotely----make-buildmicrobencho-to-generate-the-optimization-report-It’ll-show-up-in-the-terminal-and-STDOUTtxt-Paste-in-the-lines-that-contain-the-string-microbenchcpp-below-there-will-be-less-than-10-of-them"><span class="octicon octicon-link"></span></a><span>P1 (1pts) Add </span><code>-O3 -fopt-info-vec-optimized</code><span> to </span><code>MICROBENCH_OPTIMIZE</code><span> in </span><code>config.env</code><span> and then </span><code>runlab --run-git-remotely -- make build/microbench.o</code><span> to generate the optimization report.  It’ll show up in the terminal and </span><code>STDOUT.txt</code><span>.  Paste in the lines that contain the string </span><code>microbench.cpp</code><span> below (there will be less than 10 of them).</span></h4><pre><code>
build/microbench.cpp:46:13: note: loop vectorized
build/microbench.cpp:97:13: note: loop vectorized
build/microbench.cpp:211:25: note: basic block vectorized
build/microbench.cpp:74:12: note: loop vectorized
build/microbench.cpp:117:12: note: loop vectorized



</code></pre><h4 id="P2-1pts-Which-functions-contain-loops-that-were-vectorized" data-id="P2-1pts-Which-functions-contain-loops-that-were-vectorized"><a class="anchor hidden-xs" href="#P2-1pts-Which-functions-contain-loops-that-were-vectorized" title="P2-1pts-Which-functions-contain-loops-that-were-vectorized"><span class="octicon octicon-link"></span></a><span>P2 (1pts) Which functions contain loops that were vectorized?</span></h4><pre><code>serial_improved
openmp_simd
openmp_threads
openmp_threads_simd

</code></pre><p><span>Set </span><code>MICROBENCH_CMD_LINE_ARGS=--stat-set PE.cfg --impl openmp_simd serial</code><span> (leave </span><code>MICROBENCH_OPTIMIZE</code><span> as it is) and then </span><code>runlab --run-by-proxy -- make microbench.csv</code><span> (or commit and use </span><code>--run-git-remotely</code><span>).  Use the resulting </span><code>microbench.csv</code><span> to answer the following question.</span></p><h4 id="P3-3pt-Compute-the-impact-of-SIMD-on-the-following-terms-of-the-performance-equation-using-the-data-for-openmp_simd-and-serial-For-each-term-compute-value-for-serialvalue-for-openmp_simd" data-id="P3-3pt-Compute-the-impact-of-SIMD-on-the-following-terms-of-the-performance-equation-using-the-data-for-openmp_simd-and-serial-For-each-term-compute-value-for-serialvalue-for-openmp_simd"><a class="anchor hidden-xs" href="#P3-3pt-Compute-the-impact-of-SIMD-on-the-following-terms-of-the-performance-equation-using-the-data-for-openmp_simd-and-serial-For-each-term-compute-value-for-serialvalue-for-openmp_simd" title="P3-3pt-Compute-the-impact-of-SIMD-on-the-following-terms-of-the-performance-equation-using-the-data-for-openmp_simd-and-serial-For-each-term-compute-value-for-serialvalue-for-openmp_simd"><span class="octicon octicon-link"></span></a><span>P3 (3pt) Compute the impact of SIMD on the following terms of the performance equation using the data for </span><code>openmp_simd</code><span> and </span><code>serial</code><span>.  For each term, compute </span><code>(value for serial)/(value for openmp_simd)</code><span>.</span></h4><pre><code>
omp_threads|size    |function   |IC      |cycles  |runtime|PAPI_REF_CYC|MHz  |IPC  |CT      |CPI  |ET  |
-----------|--------|-----------|--------|--------|-------|------------|-----|-----|--------|-----|----|
1.0        |5.37e+08|openmp_simd|4.16e+09|5.16e+09|2.76   |4.3e+09     |2e+03|0.806|5.35e-10|1.24 |2.76|
1.0        |5.37e+08|serial     |1.23e+10|1.07e+10|5.12   |8.98e+09    |2e+03|1.15 |4.77e-10|0.869|5.12|


IC: 12.3/4.16 = 2.96
CT: 4.77/5.35 = 0.89
CPI: 0.869/1.24 = 0.70
ET: 5.12/2.76 = 1.85
</code></pre><h4 id="P4-2pt-If-Intel-improved-their-processors-so-that-the-CPI-for-vector-instructions-matched-that-of-normal-instructions-how-much-speedup-would-openmp_simd-achieve-relative-to-serial" data-id="P4-2pt-If-Intel-improved-their-processors-so-that-the-CPI-for-vector-instructions-matched-that-of-normal-instructions-how-much-speedup-would-openmp_simd-achieve-relative-to-serial"><a class="anchor hidden-xs" href="#P4-2pt-If-Intel-improved-their-processors-so-that-the-CPI-for-vector-instructions-matched-that-of-normal-instructions-how-much-speedup-would-openmp_simd-achieve-relative-to-serial" title="P4-2pt-If-Intel-improved-their-processors-so-that-the-CPI-for-vector-instructions-matched-that-of-normal-instructions-how-much-speedup-would-openmp_simd-achieve-relative-to-serial"><span class="octicon octicon-link"></span></a><span>P4 (2pt) If Intel improved their processors so that the CPI for vector instructions matched that of normal instructions, how much speedup would </span><code>openmp_simd</code><span> achieve relative to </span><code>serial</code><span>?</span></h4><pre><code>Speedup: (1.23*4.77*cpi)/(4.16*0.535*cpi) = 2.63
</code></pre><h4 id="P5-10pt-Here’s-10-free-points-because-we-couldn’t-get-vectorization-to-do-anything-useful-on-our-code-base-Put-whatever-you’d-like-below" data-id="P5-10pt-Here’s-10-free-points-because-we-couldn’t-get-vectorization-to-do-anything-useful-on-our-code-base-Put-whatever-you’d-like-below"><a class="anchor hidden-xs" href="#P5-10pt-Here’s-10-free-points-because-we-couldn’t-get-vectorization-to-do-anything-useful-on-our-code-base-Put-whatever-you’d-like-below" title="P5-10pt-Here’s-10-free-points-because-we-couldn’t-get-vectorization-to-do-anything-useful-on-our-code-base-Put-whatever-you’d-like-below"><span class="octicon octicon-link"></span></a><span>P5 (10pt)  Here’s 10 free points because we couldn’t get vectorization to do anything useful on our code base.  Put whatever you’d like below.</span></h4><pre><code>+10





</code></pre><hr><h1 id="YOU-ARE-DONE-PLEASE-ENJOY-YOUR-SUMMER" data-id="YOU-ARE-DONE-PLEASE-ENJOY-YOUR-SUMMER"><a class="anchor hidden-xs" href="#YOU-ARE-DONE-PLEASE-ENJOY-YOUR-SUMMER" title="YOU-ARE-DONE-PLEASE-ENJOY-YOUR-SUMMER"><span class="octicon octicon-link"></span></a><span>YOU ARE DONE!  PLEASE ENJOY YOUR SUMMER!</span></h1><hr></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li><a href="#Solutions-Final-Project-Part-1" title="Solutions: Final Project Part 1">Solutions: Final Project Part 1</a><ul class="nav">
<li><a href="#Experience--O3" title="Experience -O3">Experience -O3</a><ul class="nav">
<li><a href="#P1-1pt-Provide-the-runtime-for-train_model-reported-in-benchmarkcsv" title="P1 (1pt): Provide the runtime for train_model reported in benchmark.csv.">P1 (1pt): Provide the runtime for train_model reported in benchmark.csv.</a></li>
<li><a href="#P1-1pt-Provide-the-runtime-for-train_model-in-benchmarkcsv" title="P1 (1pt): Provide the runtime for train_model in benchmark.csv.">P1 (1pt): Provide the runtime for train_model in benchmark.csv.</a></li>
</ul>
</li>
<li><a href="#Get-Yourself-a-Map" title="Get Yourself a Map">Get Yourself a Map</a><ul class="nav">
<li><a href="#P3-3pt-List-the-functions-as-listed-in-benchmarkgprof-that-combined-to-account-for-99-of-the-total-execution-time-Report-the-percent-proportions-as-well" title="P3 (3pt): List the functions (as listed in benchmark.gprof) that combined to account for 99% of the total execution time. Report the percent proportions as well.">P3 (3pt): List the functions (as listed in benchmark.gprof) that combined to account for 99% of the total execution time. Report the percent proportions as well.</a></li>
</ul>
</li>
<li><a href="#Tile-fc_layer_tactivate" title="Tile fc_layer_t::activate">Tile fc_layer_t::activate</a><ul class="nav">
<li><a href="#P3-3pt-Write-the-runlab-command-and-the-values-of-CMD_LINE_ARGS-and-IMPL_SEL_ARGS-used-to-compare-your-optimization-with-the-original-code" title="P3 (3pt) Write the runlab command and the values of CMD_LINE_ARGS and IMPL_SEL_ARGS used to compare your optimization with the original code">P3 (3pt) Write the runlab command and the values of CMD_LINE_ARGS and IMPL_SEL_ARGS used to compare your optimization with the original code</a></li>
<li><a href="#P4-1pt-Note-down-the-both-execution-times-and-calculate-the-speedup" title="P4 (1pt) Note down the both execution times, and calculate the speedup">P4 (1pt) Note down the both execution times, and calculate the speedup</a></li>
<li><a href="#P5-4pt-Use---param-to-explore-the-range-of-tiling-sizes-for-activate-Draw-a-graph-that-shows-the-impact-on-execution-time-of-tiling-I-and-N-at-tile-sizes-from-1-to-128-all-combinations-Make-sure-it-is-clearly-labeled-legible-You-are-plotting-execution-time-against-two-variables-so-you-will-need-to-account-for-that-in-the-graph" title="P5 (4pt) Use --param* to explore the range of tiling sizes for activate().  Draw a graph that shows the impact on execution time of tiling I and N at tile sizes from 1 to 128 (all combinations).  Make sure it is clearly labeled legible.  You are plotting execution time against two variables, so you will need to account for that in the graph.">P5 (4pt) Use --param* to explore the range of tiling sizes for activate().  Draw a graph that shows the impact on execution time of tiling I and N at tile sizes from 1 to 128 (all combinations).  Make sure it is clearly labeled legible.  You are plotting execution time against two variables, so you will need to account for that in the graph.</a></li>
<li><a href="#P6-2pt-Based-on-your-data-what-are-the-optimal-tile-sizes-How-much-speedup-do-the-optimal-sizes-provide-relative-to-the-performance-you-measured-for-P4" title="P6 (2pt) Based on your data, what are the optimal tile sizes?  How much speedup do the optimal sizes provide relative to the performance you measured for P4?">P6 (2pt) Based on your data, what are the optimal tile sizes?  How much speedup do the optimal sizes provide relative to the performance you measured for P4?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Solutions-Final-Project-Part-2---Threads" title="Solutions: Final Project Part 2 - Threads">Solutions: Final Project Part 2 - Threads</a><ul class="nav">
<li class="invisable-node"><ul class="nav">
<li><a href="#P1-1pt-Which-implementation-provide-the-best-performance-The-worst" title="P1 (1pt): Which implementation provide the best performance? The worst?">P1 (1pt): Which implementation provide the best performance? The worst?</a></li>
<li><a href="#P2-10pts-Draw-5-graphs-one-for-each-of-the-5-implementations-calc_grads_thread_baseline-and-the-four-variations-Each-one-should-plot-the-normalized-values-for-the-first-7-values-misses-through-ET-in-the-table-above-in-the-data-you-collected-above-y-axis-vs-thread-count-x-axis-The-graphs-their-axes-and-their-legends-should-be-clearly-labeled-eg-‘calc_grads_thread_baseline_nn’-I’ll-do-an-example-of-how-to-draw-these-graphs-efficiently-in-class" title="P2 (10pts):  Draw 5 graphs, one for each of the 5 implementations (calc_grads_thread_baseline() and the four variations).  Each one should plot the normalized values for the first 7 values (misses through ET in the table above) in the data you collected above (y-axis) vs. thread count (x-axis).  The graphs, their axes, and their legends should be clearly labeled (e.g., ‘calc_grads_thread_baseline_nn()’).  I’ll do an example of how to draw these graphs efficiently in class.">P2 (10pts):  Draw 5 graphs, one for each of the 5 implementations (calc_grads_thread_baseline() and the four variations).  Each one should plot the normalized values for the first 7 values (misses through ET in the table above) in the data you collected above (y-axis) vs. thread count (x-axis).  The graphs, their axes, and their legends should be clearly labeled (e.g., ‘calc_grads_thread_baseline_nn()’).  I’ll do an example of how to draw these graphs efficiently in class.</a></li>
<li><a href="#P3-1-pt-Best-Implementation-and-thread-count" title="P3 (1 pt): Best Implementation and thread count">P3 (1 pt): Best Implementation and thread count</a></li>
<li><a href="#P4-2-pts-Consider-Version-3-b-loop-Use-the-Moneta-trace-to-determine-aptly-how-many-kBs-of-grads_out-each-thread-accesses-and-roughly-how-many-times-it-accesses-those-bytes-Provide-and-label-one-screen-capture-how-these-values-were-arrived-at" title="P4 (2 pts): Consider Version 3 (b loop). Use the Moneta trace to determine aptly how many kBs of grads_out each thread accesses and roughly how many times it accesses those bytes. Provide and label one screen capture how these values were arrived at.">P4 (2 pts): Consider Version 3 (b loop). Use the Moneta trace to determine aptly how many kBs of grads_out each thread accesses and roughly how many times it accesses those bytes. Provide and label one screen capture how these values were arrived at.</a></li>
<li><a href="#P5-2-pts-Consider-Version-3-b-loop-Provide-a-screen-capture-of-weights-Approximately-how-large-is-weights-tensor-in-kB" title="P5 (2 pts): Consider Version 3 (b loop). Provide a screen capture of weights. Approximately, how large is weights tensor in kB?">P5 (2 pts): Consider Version 3 (b loop). Provide a screen capture of weights. Approximately, how large is weights tensor in kB?</a></li>
<li><a href="#P6-2-pts-What-did-you-learn-from-P4-and-P5-that-could-explain-the-high-CPI-for-version-3-b-loop" title="P6 (2 pts): What did you learn from P4 and P5 that could explain the high CPI for version 3 (b loop)?">P6 (2 pts): What did you learn from P4 and P5 that could explain the high CPI for version 3 (b loop)?</a></li>
<li><a href="#P7-2-pts-Consider-calc_grads_thread_baseline_n-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-How-many-times-does-it-accesses-each-entry-of-the-tensor-Provide-and-label-a-Moneta-screen-capture-that-supports-your-conclusions" title="P7 (2 pts): Consider calc_grads_thread_baseline_n() How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? How many times does it accesses each entry of the tensor? Provide and label a Moneta screen capture that supports your conclusions.">P7 (2 pts): Consider calc_grads_thread_baseline_n() How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? How many times does it accesses each entry of the tensor? Provide and label a Moneta screen capture that supports your conclusions.</a></li>
<li><a href="#P8-2-pts-Consider-calc_grads_thread_baseline_n-What’s-the-ratio-of-IC-on-calc_grads_thread_baseline-to-IC-on-calc_grads_thread_baseline_n-with-1-thread-Paste-in-a-copy-of-the-C-code-that-corresponds-to-the-extra-instructions" title="P8 (2 pts) Consider calc_grads_thread_baseline_n(). What’s the ratio of IC on calc_grads_thread_baseline() to IC on calc_grads_thread_baseline_n() with 1 thread? Paste in a copy of the C++ code that corresponds to the extra instructions.">P8 (2 pts) Consider calc_grads_thread_baseline_n(). What’s the ratio of IC on calc_grads_thread_baseline() to IC on calc_grads_thread_baseline_n() with 1 thread? Paste in a copy of the C++ code that corresponds to the extra instructions.</a></li>
<li><a href="#P9-2-pts-Consider-calc_grads_thread_baseline_i-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-Give-your-answer-in-KB-Provide-and-label-a-screen-capture-illustrating-your-conclusion" title="P9 (2 pts) Consider calc_grads_thread_baseline_i(). How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? Give your answer in KB. Provide and label a screen capture illustrating your conclusion.">P9 (2 pts) Consider calc_grads_thread_baseline_i(). How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? Give your answer in KB. Provide and label a screen capture illustrating your conclusion.</a></li>
<li><a href="#P10-2-pts-Consider-calc_grads_thread_baseline_i-How-much-in-KB-of-grads_out-tensor-is-does-each-thread-access-Provide-and-label-a-screen-capture-illustrating-your-conclusion" title="P10 (2 pts) Consider calc_grads_thread_baseline_i(). How much (in KB) of grads_out tensor is does each thread access? Provide and label a screen capture illustrating your conclusion.">P10 (2 pts) Consider calc_grads_thread_baseline_i(). How much (in KB) of grads_out tensor is does each thread access? Provide and label a screen capture illustrating your conclusion.</a></li>
<li><a href="#P11-2pts-Use-your-answers-to-P9-and-P10-and-similar-measurements-of-the-trace-of-calc_grads_thread_baseline-to-explain-the-difference-between-the-number-of-misses-in-calc_grads_thread_baseline_i-and-calc_grads_thread_baseline-Two-sentences-max" title="P11 (2pts) Use your answers to P9 and P10 and similar measurements of the trace of calc_grads_thread_baseline() to explain the difference between the number of misses in calc_grads_thread_baseline_i() and calc_grads_thread_baseline(). Two sentences max.">P11 (2pts) Use your answers to P9 and P10 and similar measurements of the trace of calc_grads_thread_baseline() to explain the difference between the number of misses in calc_grads_thread_baseline_i() and calc_grads_thread_baseline(). Two sentences max.</a></li>
<li><a href="#P12-5pts-Compare-the-data-for-calc_grads_thread_baseline_nn-and-calc_grads_thread_baseline_i-with-4-threads-using-all-three-terms-of-the-PE-IC-CPI-and-CT-For-each-term-compute-value-for-calc_grads_thread_baseline_ivalue-for-calc_grads_thread_baseline_nn-Which-term-explains-calc_grads_thread_baseline_nns-lower-ET-What-could-be-one-underlying-cause-2-sentences-max" title="P12 (5pts) Compare the data for calc_grads_thread_baseline_nn() and calc_grads_thread_baseline_i() with 4 threads using all three terms of the PE (IC, CPI, and CT). For each term compute (value for calc_grads_thread_baseline_i)/(value for calc_grads_thread_baseline_nn). Which term explains calc_grads_thread_baseline_nn()'s lower ET? What could be one underlying cause? (2 sentences max)">P12 (5pts) Compare the data for calc_grads_thread_baseline_nn() and calc_grads_thread_baseline_i() with 4 threads using all three terms of the PE (IC, CPI, and CT). For each term compute (value for calc_grads_thread_baseline_i)/(value for calc_grads_thread_baseline_nn). Which term explains calc_grads_thread_baseline_nn()'s lower ET? What could be one underlying cause? (2 sentences max)</a></li>
</ul>
</li>
</ul>
</li>
<li class=""><a href="#Solutions-Final-Project-Part-3---Vectors" title="Solutions: Final Project Part 3 - Vectors">Solutions: Final Project Part 3 - Vectors</a><ul class="nav">
<li class="invisable-node"><ul class="nav">
<li><a href="#P1-1pts-Add--O3--fopt-info-vec-optimized-to-MICROBENCH_OPTIMIZE-in-configenv-and-then-runlab---run-git-remotely----make-buildmicrobencho-to-generate-the-optimization-report-It’ll-show-up-in-the-terminal-and-STDOUTtxt-Paste-in-the-lines-that-contain-the-string-microbenchcpp-below-there-will-be-less-than-10-of-them" title="P1 (1pts) Add -O3 -fopt-info-vec-optimized to MICROBENCH_OPTIMIZE in config.env and then runlab --run-git-remotely -- make build/microbench.o to generate the optimization report.  It’ll show up in the terminal and STDOUT.txt.  Paste in the lines that contain the string microbench.cpp below (there will be less than 10 of them).">P1 (1pts) Add -O3 -fopt-info-vec-optimized to MICROBENCH_OPTIMIZE in config.env and then runlab --run-git-remotely -- make build/microbench.o to generate the optimization report.  It’ll show up in the terminal and STDOUT.txt.  Paste in the lines that contain the string microbench.cpp below (there will be less than 10 of them).</a></li>
<li><a href="#P2-1pts-Which-functions-contain-loops-that-were-vectorized" title="P2 (1pts) Which functions contain loops that were vectorized?">P2 (1pts) Which functions contain loops that were vectorized?</a></li>
<li><a href="#P3-3pt-Compute-the-impact-of-SIMD-on-the-following-terms-of-the-performance-equation-using-the-data-for-openmp_simd-and-serial-For-each-term-compute-value-for-serialvalue-for-openmp_simd" title="P3 (3pt) Compute the impact of SIMD on the following terms of the performance equation using the data for openmp_simd and serial.  For each term, compute (value for serial)/(value for openmp_simd).">P3 (3pt) Compute the impact of SIMD on the following terms of the performance equation using the data for openmp_simd and serial.  For each term, compute (value for serial)/(value for openmp_simd).</a></li>
<li><a href="#P4-2pt-If-Intel-improved-their-processors-so-that-the-CPI-for-vector-instructions-matched-that-of-normal-instructions-how-much-speedup-would-openmp_simd-achieve-relative-to-serial" title="P4 (2pt) If Intel improved their processors so that the CPI for vector instructions matched that of normal instructions, how much speedup would openmp_simd achieve relative to serial?">P4 (2pt) If Intel improved their processors so that the CPI for vector instructions matched that of normal instructions, how much speedup would openmp_simd achieve relative to serial?</a></li>
<li><a href="#P5-10pt-Here’s-10-free-points-because-we-couldn’t-get-vectorization-to-do-anything-useful-on-our-code-base-Put-whatever-you’d-like-below" title="P5 (10pt)  Here’s 10 free points because we couldn’t get vectorization to do anything useful on our code base.  Put whatever you’d like below.">P5 (10pt)  Here’s 10 free points because we couldn’t get vectorization to do anything useful on our code base.  Put whatever you’d like below.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#YOU-ARE-DONE-PLEASE-ENJOY-YOUR-SUMMER" title="YOU ARE DONE!  PLEASE ENJOY YOUR SUMMER!">YOU ARE DONE!  PLEASE ENJOY YOUR SUMMER!</a></li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;" null null>
        <div class="toc"><ul class="nav">
<li><a href="#Solutions-Final-Project-Part-1" title="Solutions: Final Project Part 1">Solutions: Final Project Part 1</a><ul class="nav">
<li><a href="#Experience--O3" title="Experience -O3">Experience -O3</a><ul class="nav">
<li><a href="#P1-1pt-Provide-the-runtime-for-train_model-reported-in-benchmarkcsv" title="P1 (1pt): Provide the runtime for train_model reported in benchmark.csv.">P1 (1pt): Provide the runtime for train_model reported in benchmark.csv.</a></li>
<li><a href="#P1-1pt-Provide-the-runtime-for-train_model-in-benchmarkcsv" title="P1 (1pt): Provide the runtime for train_model in benchmark.csv.">P1 (1pt): Provide the runtime for train_model in benchmark.csv.</a></li>
</ul>
</li>
<li><a href="#Get-Yourself-a-Map" title="Get Yourself a Map">Get Yourself a Map</a><ul class="nav">
<li><a href="#P3-3pt-List-the-functions-as-listed-in-benchmarkgprof-that-combined-to-account-for-99-of-the-total-execution-time-Report-the-percent-proportions-as-well" title="P3 (3pt): List the functions (as listed in benchmark.gprof) that combined to account for 99% of the total execution time. Report the percent proportions as well.">P3 (3pt): List the functions (as listed in benchmark.gprof) that combined to account for 99% of the total execution time. Report the percent proportions as well.</a></li>
</ul>
</li>
<li><a href="#Tile-fc_layer_tactivate" title="Tile fc_layer_t::activate">Tile fc_layer_t::activate</a><ul class="nav">
<li><a href="#P3-3pt-Write-the-runlab-command-and-the-values-of-CMD_LINE_ARGS-and-IMPL_SEL_ARGS-used-to-compare-your-optimization-with-the-original-code" title="P3 (3pt) Write the runlab command and the values of CMD_LINE_ARGS and IMPL_SEL_ARGS used to compare your optimization with the original code">P3 (3pt) Write the runlab command and the values of CMD_LINE_ARGS and IMPL_SEL_ARGS used to compare your optimization with the original code</a></li>
<li><a href="#P4-1pt-Note-down-the-both-execution-times-and-calculate-the-speedup" title="P4 (1pt) Note down the both execution times, and calculate the speedup">P4 (1pt) Note down the both execution times, and calculate the speedup</a></li>
<li><a href="#P5-4pt-Use---param-to-explore-the-range-of-tiling-sizes-for-activate-Draw-a-graph-that-shows-the-impact-on-execution-time-of-tiling-I-and-N-at-tile-sizes-from-1-to-128-all-combinations-Make-sure-it-is-clearly-labeled-legible-You-are-plotting-execution-time-against-two-variables-so-you-will-need-to-account-for-that-in-the-graph" title="P5 (4pt) Use --param* to explore the range of tiling sizes for activate().  Draw a graph that shows the impact on execution time of tiling I and N at tile sizes from 1 to 128 (all combinations).  Make sure it is clearly labeled legible.  You are plotting execution time against two variables, so you will need to account for that in the graph.">P5 (4pt) Use --param* to explore the range of tiling sizes for activate().  Draw a graph that shows the impact on execution time of tiling I and N at tile sizes from 1 to 128 (all combinations).  Make sure it is clearly labeled legible.  You are plotting execution time against two variables, so you will need to account for that in the graph.</a></li>
<li><a href="#P6-2pt-Based-on-your-data-what-are-the-optimal-tile-sizes-How-much-speedup-do-the-optimal-sizes-provide-relative-to-the-performance-you-measured-for-P4" title="P6 (2pt) Based on your data, what are the optimal tile sizes?  How much speedup do the optimal sizes provide relative to the performance you measured for P4?">P6 (2pt) Based on your data, what are the optimal tile sizes?  How much speedup do the optimal sizes provide relative to the performance you measured for P4?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#Solutions-Final-Project-Part-2---Threads" title="Solutions: Final Project Part 2 - Threads">Solutions: Final Project Part 2 - Threads</a><ul class="nav">
<li class="invisable-node"><ul class="nav">
<li><a href="#P1-1pt-Which-implementation-provide-the-best-performance-The-worst" title="P1 (1pt): Which implementation provide the best performance? The worst?">P1 (1pt): Which implementation provide the best performance? The worst?</a></li>
<li><a href="#P2-10pts-Draw-5-graphs-one-for-each-of-the-5-implementations-calc_grads_thread_baseline-and-the-four-variations-Each-one-should-plot-the-normalized-values-for-the-first-7-values-misses-through-ET-in-the-table-above-in-the-data-you-collected-above-y-axis-vs-thread-count-x-axis-The-graphs-their-axes-and-their-legends-should-be-clearly-labeled-eg-‘calc_grads_thread_baseline_nn’-I’ll-do-an-example-of-how-to-draw-these-graphs-efficiently-in-class" title="P2 (10pts):  Draw 5 graphs, one for each of the 5 implementations (calc_grads_thread_baseline() and the four variations).  Each one should plot the normalized values for the first 7 values (misses through ET in the table above) in the data you collected above (y-axis) vs. thread count (x-axis).  The graphs, their axes, and their legends should be clearly labeled (e.g., ‘calc_grads_thread_baseline_nn()’).  I’ll do an example of how to draw these graphs efficiently in class.">P2 (10pts):  Draw 5 graphs, one for each of the 5 implementations (calc_grads_thread_baseline() and the four variations).  Each one should plot the normalized values for the first 7 values (misses through ET in the table above) in the data you collected above (y-axis) vs. thread count (x-axis).  The graphs, their axes, and their legends should be clearly labeled (e.g., ‘calc_grads_thread_baseline_nn()’).  I’ll do an example of how to draw these graphs efficiently in class.</a></li>
<li><a href="#P3-1-pt-Best-Implementation-and-thread-count" title="P3 (1 pt): Best Implementation and thread count">P3 (1 pt): Best Implementation and thread count</a></li>
<li><a href="#P4-2-pts-Consider-Version-3-b-loop-Use-the-Moneta-trace-to-determine-aptly-how-many-kBs-of-grads_out-each-thread-accesses-and-roughly-how-many-times-it-accesses-those-bytes-Provide-and-label-one-screen-capture-how-these-values-were-arrived-at" title="P4 (2 pts): Consider Version 3 (b loop). Use the Moneta trace to determine aptly how many kBs of grads_out each thread accesses and roughly how many times it accesses those bytes. Provide and label one screen capture how these values were arrived at.">P4 (2 pts): Consider Version 3 (b loop). Use the Moneta trace to determine aptly how many kBs of grads_out each thread accesses and roughly how many times it accesses those bytes. Provide and label one screen capture how these values were arrived at.</a></li>
<li><a href="#P5-2-pts-Consider-Version-3-b-loop-Provide-a-screen-capture-of-weights-Approximately-how-large-is-weights-tensor-in-kB" title="P5 (2 pts): Consider Version 3 (b loop). Provide a screen capture of weights. Approximately, how large is weights tensor in kB?">P5 (2 pts): Consider Version 3 (b loop). Provide a screen capture of weights. Approximately, how large is weights tensor in kB?</a></li>
<li><a href="#P6-2-pts-What-did-you-learn-from-P4-and-P5-that-could-explain-the-high-CPI-for-version-3-b-loop" title="P6 (2 pts): What did you learn from P4 and P5 that could explain the high CPI for version 3 (b loop)?">P6 (2 pts): What did you learn from P4 and P5 that could explain the high CPI for version 3 (b loop)?</a></li>
<li><a href="#P7-2-pts-Consider-calc_grads_thread_baseline_n-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-How-many-times-does-it-accesses-each-entry-of-the-tensor-Provide-and-label-a-Moneta-screen-capture-that-supports-your-conclusions" title="P7 (2 pts): Consider calc_grads_thread_baseline_n() How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? How many times does it accesses each entry of the tensor? Provide and label a Moneta screen capture that supports your conclusions.">P7 (2 pts): Consider calc_grads_thread_baseline_n() How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? How many times does it accesses each entry of the tensor? Provide and label a Moneta screen capture that supports your conclusions.</a></li>
<li><a href="#P8-2-pts-Consider-calc_grads_thread_baseline_n-What’s-the-ratio-of-IC-on-calc_grads_thread_baseline-to-IC-on-calc_grads_thread_baseline_n-with-1-thread-Paste-in-a-copy-of-the-C-code-that-corresponds-to-the-extra-instructions" title="P8 (2 pts) Consider calc_grads_thread_baseline_n(). What’s the ratio of IC on calc_grads_thread_baseline() to IC on calc_grads_thread_baseline_n() with 1 thread? Paste in a copy of the C++ code that corresponds to the extra instructions.">P8 (2 pts) Consider calc_grads_thread_baseline_n(). What’s the ratio of IC on calc_grads_thread_baseline() to IC on calc_grads_thread_baseline_n() with 1 thread? Paste in a copy of the C++ code that corresponds to the extra instructions.</a></li>
<li><a href="#P9-2-pts-Consider-calc_grads_thread_baseline_i-How-much-of-the-weights-tensor-does-each-thread-access-repeatedly-before-moving-onto-more-data-ie-how-big-is-it’s-working-set-Give-your-answer-in-KB-Provide-and-label-a-screen-capture-illustrating-your-conclusion" title="P9 (2 pts) Consider calc_grads_thread_baseline_i(). How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? Give your answer in KB. Provide and label a screen capture illustrating your conclusion.">P9 (2 pts) Consider calc_grads_thread_baseline_i(). How much of the weights tensor does each thread access repeatedly before moving onto more data (i.e., how big is it’s working set)? Give your answer in KB. Provide and label a screen capture illustrating your conclusion.</a></li>
<li><a href="#P10-2-pts-Consider-calc_grads_thread_baseline_i-How-much-in-KB-of-grads_out-tensor-is-does-each-thread-access-Provide-and-label-a-screen-capture-illustrating-your-conclusion" title="P10 (2 pts) Consider calc_grads_thread_baseline_i(). How much (in KB) of grads_out tensor is does each thread access? Provide and label a screen capture illustrating your conclusion.">P10 (2 pts) Consider calc_grads_thread_baseline_i(). How much (in KB) of grads_out tensor is does each thread access? Provide and label a screen capture illustrating your conclusion.</a></li>
<li><a href="#P11-2pts-Use-your-answers-to-P9-and-P10-and-similar-measurements-of-the-trace-of-calc_grads_thread_baseline-to-explain-the-difference-between-the-number-of-misses-in-calc_grads_thread_baseline_i-and-calc_grads_thread_baseline-Two-sentences-max" title="P11 (2pts) Use your answers to P9 and P10 and similar measurements of the trace of calc_grads_thread_baseline() to explain the difference between the number of misses in calc_grads_thread_baseline_i() and calc_grads_thread_baseline(). Two sentences max.">P11 (2pts) Use your answers to P9 and P10 and similar measurements of the trace of calc_grads_thread_baseline() to explain the difference between the number of misses in calc_grads_thread_baseline_i() and calc_grads_thread_baseline(). Two sentences max.</a></li>
<li><a href="#P12-5pts-Compare-the-data-for-calc_grads_thread_baseline_nn-and-calc_grads_thread_baseline_i-with-4-threads-using-all-three-terms-of-the-PE-IC-CPI-and-CT-For-each-term-compute-value-for-calc_grads_thread_baseline_ivalue-for-calc_grads_thread_baseline_nn-Which-term-explains-calc_grads_thread_baseline_nns-lower-ET-What-could-be-one-underlying-cause-2-sentences-max" title="P12 (5pts) Compare the data for calc_grads_thread_baseline_nn() and calc_grads_thread_baseline_i() with 4 threads using all three terms of the PE (IC, CPI, and CT). For each term compute (value for calc_grads_thread_baseline_i)/(value for calc_grads_thread_baseline_nn). Which term explains calc_grads_thread_baseline_nn()'s lower ET? What could be one underlying cause? (2 sentences max)">P12 (5pts) Compare the data for calc_grads_thread_baseline_nn() and calc_grads_thread_baseline_i() with 4 threads using all three terms of the PE (IC, CPI, and CT). For each term compute (value for calc_grads_thread_baseline_i)/(value for calc_grads_thread_baseline_nn). Which term explains calc_grads_thread_baseline_nn()'s lower ET? What could be one underlying cause? (2 sentences max)</a></li>
</ul>
</li>
</ul>
</li>
<li class=""><a href="#Solutions-Final-Project-Part-3---Vectors" title="Solutions: Final Project Part 3 - Vectors">Solutions: Final Project Part 3 - Vectors</a><ul class="nav">
<li class="invisable-node"><ul class="nav">
<li><a href="#P1-1pts-Add--O3--fopt-info-vec-optimized-to-MICROBENCH_OPTIMIZE-in-configenv-and-then-runlab---run-git-remotely----make-buildmicrobencho-to-generate-the-optimization-report-It’ll-show-up-in-the-terminal-and-STDOUTtxt-Paste-in-the-lines-that-contain-the-string-microbenchcpp-below-there-will-be-less-than-10-of-them" title="P1 (1pts) Add -O3 -fopt-info-vec-optimized to MICROBENCH_OPTIMIZE in config.env and then runlab --run-git-remotely -- make build/microbench.o to generate the optimization report.  It’ll show up in the terminal and STDOUT.txt.  Paste in the lines that contain the string microbench.cpp below (there will be less than 10 of them).">P1 (1pts) Add -O3 -fopt-info-vec-optimized to MICROBENCH_OPTIMIZE in config.env and then runlab --run-git-remotely -- make build/microbench.o to generate the optimization report.  It’ll show up in the terminal and STDOUT.txt.  Paste in the lines that contain the string microbench.cpp below (there will be less than 10 of them).</a></li>
<li><a href="#P2-1pts-Which-functions-contain-loops-that-were-vectorized" title="P2 (1pts) Which functions contain loops that were vectorized?">P2 (1pts) Which functions contain loops that were vectorized?</a></li>
<li><a href="#P3-3pt-Compute-the-impact-of-SIMD-on-the-following-terms-of-the-performance-equation-using-the-data-for-openmp_simd-and-serial-For-each-term-compute-value-for-serialvalue-for-openmp_simd" title="P3 (3pt) Compute the impact of SIMD on the following terms of the performance equation using the data for openmp_simd and serial.  For each term, compute (value for serial)/(value for openmp_simd).">P3 (3pt) Compute the impact of SIMD on the following terms of the performance equation using the data for openmp_simd and serial.  For each term, compute (value for serial)/(value for openmp_simd).</a></li>
<li><a href="#P4-2pt-If-Intel-improved-their-processors-so-that-the-CPI-for-vector-instructions-matched-that-of-normal-instructions-how-much-speedup-would-openmp_simd-achieve-relative-to-serial" title="P4 (2pt) If Intel improved their processors so that the CPI for vector instructions matched that of normal instructions, how much speedup would openmp_simd achieve relative to serial?">P4 (2pt) If Intel improved their processors so that the CPI for vector instructions matched that of normal instructions, how much speedup would openmp_simd achieve relative to serial?</a></li>
<li><a href="#P5-10pt-Here’s-10-free-points-because-we-couldn’t-get-vectorization-to-do-anything-useful-on-our-code-base-Put-whatever-you’d-like-below" title="P5 (10pt)  Here’s 10 free points because we couldn’t get vectorization to do anything useful on our code base.  Put whatever you’d like below.">P5 (10pt)  Here’s 10 free points because we couldn’t get vectorization to do anything useful on our code base.  Put whatever you’d like below.</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#YOU-ARE-DONE-PLEASE-ENJOY-YOUR-SUMMER" title="YOU ARE DONE!  PLEASE ENJOY YOUR SUMMER!">YOU ARE DONE!  PLEASE ENJOY YOUR SUMMER!</a></li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
